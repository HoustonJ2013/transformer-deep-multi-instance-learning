{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d303f4-5124-47bf-99c0-d64ec34fab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Further investigation found the slow mnst generator is caused by slow 1d indexing on CPU\n",
    "## Switch to 2D indexing plus list comprehesion that removed those for loops speed up the generator by 6 times. \n",
    "## the data transfer time from cpu to GPU takes only a small percentage of the run time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83799c66-d434-4fa7-958b-fd86c4ced293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import (ALL_COMPLETED, ThreadPoolExecutor,\n",
    "                                as_completed, wait)\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c831ded5-f46f-4a00-9716-688282b8412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_tensor_path = \"../datasets/mnst_train_dinov2_small.pt\"\n",
    "label_tensor_path = \"../datasets/mnst_train_labels.pt\"\n",
    "embedding = torch.load(embedding_tensor_path) \n",
    "labels = torch.load(label_tensor_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4821be6-0a33-4a6f-9969-82171a631beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(embedding)\n",
    "batch_size = 128\n",
    "max_bag_length = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b1b77a04-d65a-4708-bc42-d498af6969d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_batch():\n",
    "    random_bag_lengths = np.clip(\n",
    "                    np.random.poisson(20, size=(batch_size)).astype(int),\n",
    "                    1,\n",
    "                    max_bag_length,\n",
    "                )\n",
    "    attention_mask = torch.tensor([[1]*l + [0]*(max_bag_length - l) for l in random_bag_lengths], dtype=(torch.float32))\n",
    "    batched_random_indices = np.random.randint(n, size=(batch_size, max_bag_length))\n",
    "    input_tensor = embedding[batched_random_indices]\n",
    "    label_tensor = (torch.sum((labels[batched_random_indices] == 9) * attention_mask, axis=1) >= 4).to(torch.float32)\n",
    "    return input_tensor, label_tensor, attention_mask\n",
    "\n",
    "def get_one_batch2():\n",
    "    random_bag_lengths = np.clip(\n",
    "                    np.random.poisson(20, size=(batch_size)).astype(int),\n",
    "                    1,\n",
    "                    max_bag_length,\n",
    "                )\n",
    "    attention_mask = torch.zeros((batch_size, max_bag_length), dtype=(torch.float32))\n",
    "    for i, l_ in enumerate(random_bag_lengths):\n",
    "        attention_mask[i, :l_] = 1\n",
    "    \n",
    "    batched_random_indices = np.random.randint(n, size=(batch_size, max_bag_length))\n",
    "    input_tensor = torch.zeros(\n",
    "                (batch_size, max_bag_length, 384),\n",
    "                dtype=(torch.float32),\n",
    "            )\n",
    "    for i in range(batch_size):\n",
    "        input_tensor[i] = embedding[batched_random_indices[i]]\n",
    "    label_tensor = torch.zeros((batch_size), dtype=(torch.float32))\n",
    "    for i in range(batch_size):\n",
    "        label_tensor[i] = int(\n",
    "            torch.sum(labels[batched_random_indices[i]][: random_bag_lengths[i]] == 9)\n",
    "            >= 4\n",
    "        )\n",
    "    return input_tensor, label_tensor, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fe54b230-cb27-4baf-a116-a0b1b5fee4e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2856097221374512, 1.0330467224121094)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## compute only on CPU \n",
    "output_tensor_cpu = torch.zeros((batch_size, max_bag_length, 384), dtype=(torch.float32))\n",
    "t1 = time()\n",
    "get_batch_times = []\n",
    "for i in range(500):\n",
    "    t1a = time()\n",
    "    tem, label, mask = get_one_batch()\n",
    "    t1b = time()\n",
    "    get_batch_times.append(t1b - t1a)\n",
    "    output_tensor_cpu = tem + 1\n",
    "t2 = time()\n",
    "t2 - t1, np.sum(get_batch_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ce6887e9-5305-43ac-ae84-92d790d00f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.981238842010498, 6.7260212898254395)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## compute only on CPU \n",
    "output_tensor_cpu = torch.zeros((batch_size, max_bag_length, 384), dtype=(torch.float32))\n",
    "t1 = time()\n",
    "get_batch_times = []\n",
    "for i in range(500):\n",
    "    t1a = time()\n",
    "    tem, label, mask = get_one_batch2()\n",
    "    t1b = time()\n",
    "    get_batch_times.append(t1b - t1a)\n",
    "    output_tensor_cpu = tem + 1\n",
    "t2 = time()\n",
    "t2 - t1, np.sum(get_batch_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "77d957a9-8827-43f0-8284-c3b992275194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4963743686676025"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## compute only on GPU \n",
    "output_tensor_gpu = torch.zeros((batch_size, max_bag_length, 384), dtype=(torch.float32)).cuda()\n",
    "t1 = time()\n",
    "for i in range(500):\n",
    "    t1a = time()\n",
    "    tem, label, mask = get_one_batch()\n",
    "    tem = tem.cuda(non_blocking=True)\n",
    "    output_tensor_gpu = tem + 1\n",
    "    t1b = time()\n",
    "t2 = time()\n",
    "t2 - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b1b90c3a-c236-433e-8612-a4218d229b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_bag_lengths = np.clip(\n",
    "                    np.random.poisson(20, size=(batch_size)).astype(int),\n",
    "                    1,\n",
    "                    max_bag_length,\n",
    "                )\n",
    "attention_mask = torch.tensor([[1]*l + [0]*(max_bag_length - l) for l in random_bag_lengths], dtype=(torch.float32))\n",
    "\n",
    "label_tensor = torch.zeros((batch_size), dtype=(torch.float32))\n",
    "for i in range(batch_size):\n",
    "    label_tensor[i] = int(\n",
    "        torch.sum(labels[batched_random_indices[i]][: random_bag_lengths[i]] == 9)\n",
    "        >= 4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3ef7d64f-f7b4-4258-93cb-5b8c7e5d5394",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tensor2 = (torch.sum((labels[batched_random_indices] == 9) * attention_mask, axis=1) >= 4).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9630d5b9-a00a-4290-aae7-f3c4db50fbf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(label_tensor != label_tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102b4f85-1fbd-428a-a469-0b15b2a8fce7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
