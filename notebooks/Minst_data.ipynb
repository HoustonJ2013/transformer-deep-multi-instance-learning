{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb50e48-33be-405f-ad24-22a8c84ce9de",
   "metadata": {},
   "source": [
    "## MNST image download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "674c5d93-34a4-4fdc-883d-ce1df7132d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6834dfd1-09a3-4777-9917-78deabdd5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST('../datasets',\n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ebe35d-799b-4fc5-abb5-e3304b3e34cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, <PIL.Image.Image image mode=L size=28x28>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7013e10d-8d07-4a09-8d32-003eb40af502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = [dataset[0][0], dataset[1][0]]\n",
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2c345d3-8be5-4d4c-a490-cb376c9e3603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0bfb097-b44b-473b-90fc-afc0803980a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb1015-6322-4ca5-aedb-c1294505fdc2",
   "metadata": {},
   "source": [
    "## Investigate DINO V2 from Hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e69f0b1-b4da-48d8-a8ae-7182f282a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-small')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-small')\n",
    "model.cuda()\n",
    "inputs = processor(images=imgs, return_tensors=\"pt\").to(\"cuda:0\", non_blocking=True)\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bad60f97-1f4c-4ab6-b5e0-b773c8f0dbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 257, 384]), torch.Size([2, 257, 384]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape, last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee38214-b861-4821-b7d7-3f93ea1a879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=imgs, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a5fba60-7d58-4e4b-89dc-7a348752cab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"pixel_values\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f0d05-909f-4e3c-8274-fd518f160aab",
   "metadata": {},
   "source": [
    "### Batch class encoding using DINO v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f73b5dc-a4ef-45f6-9f8d-0de22d5e92b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [06:49<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST('../datasets',\n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=None)\n",
    "batch_size = 128\n",
    "n = len(dataset)\n",
    "n_batch = (n + batch_size - 1) // batch_size\n",
    "embedding_list = []\n",
    "for batch_i in tqdm(range(n_batch)):\n",
    "    imgs = [dataset[i_][0] for i_ in range(batch_i * batch_size, (batch_i+1) * batch_size) if i_ < n]\n",
    "    inputs = processor(images=imgs, return_tensors=\"pt\").to(\"cuda:0\", non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(**inputs)[0]\n",
    "        embedding_list.append(last_hidden_states[:, 0, :].cpu()) # extract cls token embedding \n",
    "torch.save(torch.concat(embedding_list), \"../datasets/mnst_train_dinov2_small.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbb76c6c-cc48-4987-adc7-0efb62fa32b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [01:06<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST('../datasets',\n",
    "                      train=False,\n",
    "                      download=True,\n",
    "                      transform=None)\n",
    "batch_size = 128\n",
    "n = len(dataset)\n",
    "n_batch = (n + batch_size - 1) // batch_size\n",
    "embedding_list = []\n",
    "for batch_i in tqdm(range(n_batch)):\n",
    "    imgs = [dataset[i_][0] for i_ in range(batch_i * batch_size, (batch_i+1) * batch_size) if i_ < n]\n",
    "    inputs = processor(images=imgs, return_tensors=\"pt\").to(\"cuda:0\", non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(**inputs)[0]\n",
    "        embedding_list.append(last_hidden_states[:, 0, :].cpu()) # extract cls token embedding \n",
    "torch.save(torch.concat(embedding_list), \"../datasets/mnst_test_dinov2_small.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb4a396-802c-46f6-ba2e-78b7ee0010fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST('../datasets',\n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=None)\n",
    "labels = [dataset[i_][1] for i_ in range(len(dataset))]\n",
    "torch.save(torch.tensor(labels), \"../datasets/mnst_train_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8707cacd-e0a8-4da0-8797-046d8856e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST('../datasets',\n",
    "                      train=False,\n",
    "                      download=True,\n",
    "                      transform=None)\n",
    "labels = [dataset[i_][1] for i_ in range(len(dataset))]\n",
    "torch.save(torch.tensor(labels), \"../datasets/mnst_test_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d138d732-37b8-4d5f-a82b-ef0088118ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding = torch.load(\"../datasets/mnst_train_dinov2_small.pt\")\n",
    "train_labels = torch.load(\"../datasets/mnst_train_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbea39e-00f4-4832-88d6-3655fb6d8893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de0b43-6df4-4542-b079-50904974d484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
