{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7518892-2f69-490a-845b-a73ccc4b9ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The numpydataloader is very slow, compared to the random generate directly sample on the large vector\n",
    "## This notebook explore the concurrent dataloader to avoid the i/o bottle neck. \n",
    "## The old repo was saved on hdd, switching to ssd, the i/o is much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea11a6f1-3f2d-4a9e-9da5-03d24b771968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from time import time \n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed, ProcessPoolExecutor, ALL_COMPLETED\n",
    "from concurrent.futures import FIRST_COMPLETED\n",
    "from concurrent.futures import wait "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d3317d9-f95d-4c65-8802-5488a728a6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>array_path</th>\n",
       "      <th>bag_length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/MNST_train/0/0/bagLength_027_targe...</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/MNST_train/0/0/bagLength_038_targe...</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/MNST_train/0/0/bagLength_022_targe...</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          array_path  bag_length  target\n",
       "0  ../datasets/MNST_train/0/0/bagLength_027_targe...          27       1\n",
       "1  ../datasets/MNST_train/0/0/bagLength_038_targe...          38       0\n",
       "2  ../datasets/MNST_train/0/0/bagLength_022_targe...          22       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../datasets/mnst_train.csv\")\n",
    "train_df[\"array_path\"] = train_df[\"array_path\"].apply(lambda x: \"../\" + x)\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a45d408-42fd-4459-abcd-fbaef9359a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([176991, 214539, 476497, 204614, 661055, 311895, 579581, 471115,\n",
       "       937967, 753033, 672717, 153128, 349828,  35391, 250792, 323317,\n",
       "       465212, 340700, 937070, 121861, 348637, 915496,  32817, 456531,\n",
       "       864879, 615930, 649352, 315763, 755613, 871283, 280635, 251298,\n",
       "       140844, 552776, 117011, 497278,  15436, 151263, 194155, 336215,\n",
       "       621440, 874601, 746999,  77257, 858351, 761406, 396964, 676819,\n",
       "       904291, 757020, 152383, 858631, 312202, 917940, 275896, 290407,\n",
       "       802086, 252654, 920905, 712116, 169362, 200183,  50503, 838543,\n",
       "       539948, 987648, 470644, 463210, 857228, 960785, 324344, 248011,\n",
       "       455667, 468431, 956257, 597981, 276120, 973476, 392060, 659135,\n",
       "       425235, 608754, 586147, 530974, 781322,  12787, 550844, 276071,\n",
       "        52123, 855816,  83798, 371066, 173850,  58867, 274263, 274094,\n",
       "       962607, 789430, 690917, 256214])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(101)\n",
    "sample_indices = np.random.randint(len(train_df), size=(100))\n",
    "sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d6da685-58db-4e95-9c49-1277a45bd9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 1124.13it/s]\n"
     ]
    }
   ],
   "source": [
    "io_times = []\n",
    "total_times = []\n",
    "for index in tqdm(sample_indices):\n",
    "    t0 = time()\n",
    "    np_path = train_df.loc[index, \"array_path\"]\n",
    "    label = train_df.loc[index, \"target\"]\n",
    "    t1 = time()\n",
    "    np_array = np.load(np_path)\n",
    "    t2 = time()\n",
    "    np.random.shuffle(np_array)\n",
    "    bag_length = len(np_array)\n",
    "    attention_mask = torch.ones((40), dtype=(torch.float32))\n",
    "    if bag_length < 40:\n",
    "        np_array = np.pad(\n",
    "            np_array, ((0, 40 - bag_length), (0, 0)), \"constant\", constant_values=(0, 0)\n",
    "        )\n",
    "    else:\n",
    "        np_array = np_array[: 40, :]\n",
    "        attention_mask[40 :] = 0\n",
    "    t3 = time()\n",
    "    io_times.append(t2 - t1)\n",
    "    total_times.append(t3 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3b99553-f64d-4b29-9fab-47d90ee960e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5939801464288706, 0.0523991584777832, 0.08821702003479004)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(io_times)/np.mean(total_times), np.sum(io_times), np.sum(total_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70d78d19-6261-44fa-8876-bc6bfbf650df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O takes 99% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30a00d1b-f388-4e74-afce-7969ff481adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_sample(index):\n",
    "    np_path = train_df.loc[index, \"array_path\"]\n",
    "    label = train_df.loc[index, \"target\"]\n",
    "    np_array = np.load(np_path)\n",
    "    bag_length = len(np_array)\n",
    "    indices = np.arange(bag_length)\n",
    "    np.random.shuffle(indices)\n",
    "    np_array = np_array[indices]\n",
    "    attention_mask = torch.ones((40), dtype=(torch.float32))\n",
    "    if bag_length < 40:\n",
    "        np_array = np.pad(\n",
    "            np_array, ((0, 40 - bag_length), (0, 0)), \"constant\", constant_values=(0, 0)\n",
    "        )\n",
    "        attention_mask[bag_length:] = 0\n",
    "    else:\n",
    "        np_array = np_array[: 40, :]\n",
    "        \n",
    "    return torch.tensor(np_array), torch.tensor(label, dtype=torch.float32), attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "230f1e0a-ace3-4246-bbfa-c48129581694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader(batch_size=128, max_threads=100):\n",
    "    n = 1024 * 4\n",
    "    n_batch = (n + batch_size - 1) // batch_size\n",
    "    all_indices = np.random.choice(np.arange(len(train_df)), n)\n",
    "    with ThreadPoolExecutor(max_threads) as executor:\n",
    "        # submit tasks and collect futures\n",
    "        for batch_i in range(n_batch):\n",
    "            futures = [executor.submit(get_one_sample, i) for i in all_indices[batch_i*batch_size: (batch_i+1) * batch_size]]\n",
    "            inps = []\n",
    "            labels = []\n",
    "            masks = []\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                inp_, lab_, msk_ = result\n",
    "                inps.append(inp_)\n",
    "                labels.append(lab_)\n",
    "                masks.append(msk_)\n",
    "            yield torch.stack(inps), torch.stack(labels), torch.stack(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d090989e-b85d-433f-94c1-f520863700c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39.07833433151245, 4096)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time()\n",
    "total_n = 0\n",
    "inps1 = []\n",
    "for inp_, lab_, mask_ in dataloader(batch_size=4096, max_threads=2048):\n",
    "    total_n += len(inp_)\n",
    "    inps1.append(inp_)\n",
    "t2 = time()\n",
    "t2 - t1, total_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a01eb9f9-4b17-4fd2-9b9d-5d389d6b4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_v2(batch_size=128, buffer_size=512, max_threads = 100):\n",
    "    n = len(train_df.iloc[:1024 * 4])\n",
    "    n_batch = (n + batch_size - 1) // batch_size\n",
    "    i = 0\n",
    "    buffer_i = 0\n",
    "    with ThreadPoolExecutor(max_threads) as executor:\n",
    "        # submit tasks and collect future\n",
    "        futures_buffer = set(executor.submit(get_one_sample, i) for i in range(buffer_size))\n",
    "        buffer_i = buffer_size \n",
    "        inps = []\n",
    "        labels = []\n",
    "        masks = []\n",
    "        while(i < n):\n",
    "            finished, futures_buffer = wait(futures_buffer, return_when=FIRST_COMPLETED)\n",
    "            for future in finished:\n",
    "                inp_, lab_, msk_ = future.result()\n",
    "                inps.append(inp_)\n",
    "                labels.append(lab_)\n",
    "                masks.append(msk_)\n",
    "                i += 1\n",
    "                if(i % batch_size == 0):\n",
    "                    print(i, len(inps))\n",
    "                    yield torch.stack(inps), torch.stack(labels), torch.stack(masks)\n",
    "                    inps = []\n",
    "                    labels = []\n",
    "                    masks = []\n",
    "                    futures_buffer.update(executor.submit(get_one_sample, i) for i in range(buffer_i, buffer_i + batch_size))\n",
    "                    buffer_i += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5b318766-545c-4571-beb8-4fbac7756630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024 1024\n",
      "2048 1024\n",
      "3072 1024\n",
      "4096 1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18.103395462036133, 4096)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time()\n",
    "total_n = 0\n",
    "for inp_, lab_, mask_ in dataloader_v2(batch_size=1024, max_threads=800, buffer_size=2048):\n",
    "    total_n += len(inp_)\n",
    "t2 = time()\n",
    "t2 - t1, total_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5c96c73a-74f3-4d7b-b0ee-b9c08d7ef5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_v3(batch_size=128, max_threads=100):\n",
    "    n = len(train_df.iloc[:1024 * 4])\n",
    "    n_batch = (n + batch_size - 1) // batch_size\n",
    "    all_indices = np.arange(n)\n",
    "    with ProcessPoolExecutor(max_threads) as executor:\n",
    "        # submit tasks and collect futures\n",
    "        for batch_i in range(n_batch):\n",
    "            futures = [executor.submit(get_one_sample, i) for i in all_indices[batch_i*batch_size: (batch_i+1) * batch_size]]\n",
    "            inps = []\n",
    "            labels = []\n",
    "            masks = []\n",
    "            for future in as_completed(futures):\n",
    "                result = future.result()\n",
    "                inp_, lab_, msk_ = result\n",
    "                inps.append(inp_)\n",
    "                labels.append(lab_)\n",
    "                masks.append(msk_)\n",
    "            yield torch.stack(inps), torch.stack(labels), torch.stack(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b516fc8b-7a2a-4b8d-94bc-54157dd7ce53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.550877571105957, 4096)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time()\n",
    "total_n = 0\n",
    "for inp_, lab_, mask_ in dataloader_v3(batch_size=128, max_threads=50):\n",
    "    total_n += len(inp_)\n",
    "t2 = time()\n",
    "t2 - t1, total_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "590b4787-8b33-4811-85e0-4a412a0b709b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_v4(batch_size=128, max_threads=100, max_bag_length=40):\n",
    "    ## share mem\n",
    "    def get_one_sample_shared(local_i, index):\n",
    "        t0 = time()\n",
    "        np_path = train_df.loc[index, \"array_path\"]\n",
    "        label = train_df.loc[index, \"target\"]\n",
    "        t1 = time()\n",
    "        np_array = np.load(np_path)\n",
    "        bag_length = len(np_array)\n",
    "        t2 = time()\n",
    "        indices = np.arange(bag_length)\n",
    "        np.random.shuffle(indices)\n",
    "        np_array = np_array[indices]\n",
    "        t3 = time()\n",
    "        if bag_length < 40:\n",
    "            input_tensor[local_i,:bag_length, :] = torch.tensor(np_array)\n",
    "            attention_mask[local_i, bag_length:] = 0\n",
    "        else:\n",
    "            input_tensor[local_i,:, :] = torch.tensor(np_array[: 40, :])\n",
    "        label_tensor[local_i] = label \n",
    "        t4 = time()\n",
    "        # print(\"load array takes %0.4f p1 takes %0.4f p3 takes %0.4f p4 takes %0.4f\"%(t2 - t1, t1 - t0 , t3 - t2, t4 - t3))\n",
    "        \n",
    "    n = 1024 * 24\n",
    "    n_batch = (n + batch_size - 1) // batch_size\n",
    "    randint = np.random.randint(len(train_df))\n",
    "    if randint + n < len(train_df): \n",
    "        all_indices = np.arange(randint, randint + n)\n",
    "    else: \n",
    "        all_indices = np.arange(randint - n, randint)\n",
    "    with ThreadPoolExecutor(max_threads) as executor:\n",
    "        # submit tasks and collect futures\n",
    "        for batch_i in range(n_batch):\n",
    "            t0 = time()\n",
    "            attention_mask = torch.ones((batch_size, max_bag_length), dtype=(torch.float32))\n",
    "            input_tensor = torch.zeros(\n",
    "                (batch_size, max_bag_length, 384),\n",
    "                dtype=(torch.float32),\n",
    "            )\n",
    "            label_tensor = torch.zeros((batch_size), dtype=(torch.float32))\n",
    "            t1 = time()\n",
    "            # print(\"Create empty torch tensor takes %0.4f\"%(t1 - t0))\n",
    "            futures = [executor.submit(get_one_sample_shared, local_i, i) for local_i, i in enumerate(all_indices[batch_i*batch_size: (batch_i+1) * batch_size])]\n",
    "            finished, remains = wait(futures, return_when=ALL_COMPLETED)\n",
    "            t2 = time()\n",
    "            # print(\"Load and Overwrite empty torch tensor takes %0.4f\"%(t2 - t0))\n",
    "            yield input_tensor, label_tensor, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98fac356-2059-4907-8517-bbcc55122e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14.459701776504517, 24576)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time()\n",
    "total_n = 0\n",
    "inps2 = []\n",
    "masks2 = []\n",
    "for inp_, lab_, mask_ in dataloader_v4(batch_size=2048, max_threads=1024):\n",
    "    total_n += len(inp_)\n",
    "    inps2.append(inp_)\n",
    "    masks2.append(mask_)\n",
    "t2 = time()\n",
    "t2 - t1, total_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0d70cd6-0f0b-4de1-8236-3ece0317fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inps1_tensor = torch.concat(inps1)\n",
    "inps2_tensor = torch.concat(inps2)\n",
    "masks2 = torch.concat(masks2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff7099e1-9041-4191-b917-a6e9a45980a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]),\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks2[10], masks2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fbec94d-d385-4d9a-bb78-4a04058a44e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load 8192 numpy takes  3.2522 secs\n"
     ]
    }
   ],
   "source": [
    "def load_numpy(local_i, index):\n",
    "    np_path = train_df.loc[index, \"array_path\"]\n",
    "    np_array = np.load(np_path)\n",
    "max_threads = 1024\n",
    "max_bag_length = 40 \n",
    "batch_size = 2048\n",
    "t0 = time()\n",
    "n = 1024 * 8\n",
    "n_batch = (n + batch_size - 1) // batch_size\n",
    "randint = np.random.randint(len(train_df))\n",
    "if randint + n < len(train_df): \n",
    "    all_indices = np.arange(randint, randint + n)\n",
    "else: \n",
    "    all_indices = np.arange(randint - n, randint)\n",
    "with ThreadPoolExecutor(max_threads) as executor:\n",
    "    for batch_i in range(n_batch):\n",
    "        attention_mask = torch.ones((batch_size, max_bag_length), dtype=(torch.float32))\n",
    "        input_tensor = torch.zeros(\n",
    "            (batch_size, max_bag_length, 384),\n",
    "            dtype=(torch.float32),\n",
    "        )\n",
    "        label_tensor = torch.zeros((batch_size), dtype=(torch.float32))\n",
    "        futures = [executor.submit(load_numpy, local_i, i) for local_i, i in enumerate(all_indices[batch_i*batch_size: (batch_i+1) * batch_size])]\n",
    "        finished, remains = wait(futures, return_when=ALL_COMPLETED)\n",
    "t1 = time()\n",
    "print(\"Load %i numpy takes  %0.4f secs\"%(n, t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a1ea9e7-bc7b-4fb0-a868-71915936bd27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2048 * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112b62d-31ef-4ca5-b109-6ab9cb80e52d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
