{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from tdmil.modelMIL import MILAttention, TransformerMIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(model, model_path):\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_model = TransformerMIL(\n",
    "            embed_dim=384,\n",
    "            depth=4,\n",
    "            num_heads=12,\n",
    "        )\n",
    "_ = attention_model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_checkpoint(attention_model, \"model_weights/property_img_transformer_numpygenerator/checkpoint_00100.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>array_path</th>\n",
       "      <th>bag_length</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29526</th>\n",
       "      <td>datasets/image_emb/ 4340 Valencia Dr          ...</td>\n",
       "      <td>38</td>\n",
       "      <td>750000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16674</th>\n",
       "      <td>datasets/image_emb/ 8324 Black Pearl Ct       ...</td>\n",
       "      <td>24</td>\n",
       "      <td>264364.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              array_path  bag_length    target\n",
       "29526  datasets/image_emb/ 4340 Valencia Dr          ...          38  750000.0\n",
       "16674  datasets/image_emb/ 8324 Black Pearl Ct       ...          24  264364.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_csv = \"datasets/val_image_emb.csv\"\n",
    "inp_df = pd.read_csv(inp_csv)\n",
    "inp_df.sample(2, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_bag_length = 45\n",
    "array_path = inp_df.sample(2, random_state=15).iloc[0][\"array_path\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = []\n",
    "all_arrays = []\n",
    "all_torch_arrays = []\n",
    "all_torch_masks = []\n",
    "for _ in range(5):\n",
    "    np_array = np.load(array_path)\n",
    "    bag_length = len(np_array)\n",
    "    indices = np.arange(bag_length)\n",
    "    np.random.shuffle(indices)\n",
    "    np_array = np_array[indices]\n",
    "    all_arrays.append(np_array)\n",
    "    attention_mask = torch.ones((max_bag_length), dtype=torch.float32)\n",
    "    inp_torch_array = torch.zeros((max_bag_length, 384), dtype=torch.float32)\n",
    "    inp_torch_array[:bag_length, :] = torch.tensor(np_array)\n",
    "    attention_mask[bag_length:] = 0\n",
    "    all_torch_arrays.append(inp_torch_array)\n",
    "    all_torch_masks.append(attention_mask)\n",
    "    inp_torch_array = inp_torch_array.unsqueeze_(0)\n",
    "    attention_mask = attention_mask.unsqueeze_(0)\n",
    "    inp_ = inp_torch_array.cuda(non_blocking=True)\n",
    "    mask_ = attention_mask.cuda(non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        forward_result = attention_model(inp_, mask_, return_cls_token=True)\n",
    "        batch_embedding = forward_result[\"cls_token\"].clone().detach().cpu().numpy().astype(np.float32)\n",
    "    all_embeddings.append(batch_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp2_ = torch.concat(all_torch_arrays).cuda()\n",
    "mask2_ = torch.concat(all_torch_masks).cuda()\n",
    "with torch.no_grad():\n",
    "    forward_result = attention_model(inp2_, mask2_, return_cls_token=True)\n",
    "    batch_embedding2 = forward_result[\"cls_token\"].clone().detach().cpu().numpy().astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(batch_embedding2[0] != batch_embedding2[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-24.720535 , -52.081085 ,  41.67712  ,  15.15655  , -11.127977 ,\n",
       "         82.48938  , -29.966606 , -31.782497 ,  12.296479 , -72.21116  ,\n",
       "        -57.312946 , -10.943734 ,   1.1515127,  21.702269 ,  38.567696 ,\n",
       "         58.712196 ,  47.17046  ,  35.95886  , -47.635925 ,   5.275736 ],\n",
       "       dtype=float32),\n",
       " array([-24.720535 , -52.081085 ,  41.67712  ,  15.15655  , -11.127977 ,\n",
       "         82.48938  , -29.966606 , -31.782497 ,  12.296479 , -72.21116  ,\n",
       "        -57.312946 , -10.943734 ,   1.1515127,  21.702269 ,  38.567696 ,\n",
       "         58.712196 ,  47.17046  ,  35.95886  , -47.635925 ,   5.275736 ],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_embedding2[0][0:20], batch_embedding2[1][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False], device='cuda:0')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sort(inp2_[0, 0:45, 1]).values != torch.sort(inp2_[2, 0:45, 1]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask2_[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_torch_arrays[1][0][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
