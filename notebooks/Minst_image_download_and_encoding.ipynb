{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb50e48-33be-405f-ad24-22a8c84ce9de",
   "metadata": {},
   "source": [
    "## MNST image download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674c5d93-34a4-4fdc-883d-ce1df7132d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data_utils\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6834dfd1-09a3-4777-9917-78deabdd5dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST('../datasets',\n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99ebe35d-799b-4fc5-abb5-e3304b3e34cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, <PIL.Image.Image image mode=L size=28x28>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7013e10d-8d07-4a09-8d32-003eb40af502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4nGNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16Aa0wAOwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = [dataset[0][0], dataset[1][0]]\n",
    "imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2c345d3-8be5-4d4c-a490-cb376c9e3603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVR4nGNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkTVIzd2AAAAAElFTkSuQmCC",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0bfb097-b44b-473b-90fc-afc0803980a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb1015-6322-4ca5-aedb-c1294505fdc2",
   "metadata": {},
   "source": [
    "## Investigate DINO V2 from Hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e69f0b1-b4da-48d8-a8ae-7182f282a9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'http://images.cocodataset.org/val2017/000000039769.jpg'\n",
    "# image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained('facebook/dinov2-small')\n",
    "model = AutoModel.from_pretrained('facebook/dinov2-small')\n",
    "model.cuda()\n",
    "inputs = processor(images=imgs, return_tensors=\"pt\").to(\"cuda:0\", non_blocking=True)\n",
    "outputs = model(**inputs)\n",
    "last_hidden_states = outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bad60f97-1f4c-4ab6-b5e0-b773c8f0dbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 257, 384]), torch.Size([2, 257, 384]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.last_hidden_state.shape, last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bee38214-b861-4821-b7d7-3f93ea1a879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(images=imgs, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a5fba60-7d58-4e4b-89dc-7a348752cab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[\"pixel_values\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f0d05-909f-4e3c-8274-fd518f160aab",
   "metadata": {},
   "source": [
    "### Batch class encoding using DINO v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f73b5dc-a4ef-45f6-9f8d-0de22d5e92b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 469/469 [06:49<00:00,  1.15it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST('../datasets',\n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=None)\n",
    "batch_size = 128\n",
    "n = len(dataset)\n",
    "n_batch = (n + batch_size - 1) // batch_size\n",
    "embedding_list = []\n",
    "for batch_i in tqdm(range(n_batch)):\n",
    "    imgs = [dataset[i_][0] for i_ in range(batch_i * batch_size, (batch_i+1) * batch_size) if i_ < n]\n",
    "    inputs = processor(images=imgs, return_tensors=\"pt\").to(\"cuda:0\", non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(**inputs)[0]\n",
    "        embedding_list.append(last_hidden_states[:, 0, :].cpu()) # extract cls token embedding \n",
    "torch.save(torch.concat(embedding_list), \"../datasets/mnst_train_dinov2_small.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cbb76c6c-cc48-4987-adc7-0efb62fa32b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [01:06<00:00,  1.19it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST('../datasets',\n",
    "                      train=False,\n",
    "                      download=True,\n",
    "                      transform=None)\n",
    "batch_size = 128\n",
    "n = len(dataset)\n",
    "n_batch = (n + batch_size - 1) // batch_size\n",
    "embedding_list = []\n",
    "for batch_i in tqdm(range(n_batch)):\n",
    "    imgs = [dataset[i_][0] for i_ in range(batch_i * batch_size, (batch_i+1) * batch_size) if i_ < n]\n",
    "    inputs = processor(images=imgs, return_tensors=\"pt\").to(\"cuda:0\", non_blocking=True)\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(**inputs)[0]\n",
    "        embedding_list.append(last_hidden_states[:, 0, :].cpu()) # extract cls token embedding \n",
    "torch.save(torch.concat(embedding_list), \"../datasets/mnst_test_dinov2_small.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb4a396-802c-46f6-ba2e-78b7ee0010fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST('../datasets',\n",
    "                      train=True,\n",
    "                      download=True,\n",
    "                      transform=None)\n",
    "labels = [dataset[i_][1] for i_ in range(len(dataset))]\n",
    "torch.save(torch.tensor(labels), \"../datasets/mnst_train_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8707cacd-e0a8-4da0-8797-046d8856e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST('../datasets',\n",
    "                      train=False,\n",
    "                      download=True,\n",
    "                      transform=None)\n",
    "labels = [dataset[i_][1] for i_ in range(len(dataset))]\n",
    "torch.save(torch.tensor(labels), \"../datasets/mnst_test_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d138d732-37b8-4d5f-a82b-ef0088118ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embedding = torch.load(\"../datasets/mnst_train_dinov2_small.pt\")\n",
    "train_labels = torch.load(\"../datasets/mnst_train_labels.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c3e61-c050-40cf-96d9-f2a0f7888a4f",
   "metadata": {},
   "source": [
    "## Simulate real bag dataformat with MNST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09de0b43-6df4-4542-b079-50904974d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simulate the bag data with encoding only \n",
    "## For each data sample, it has random variable bag length, and the data contents should be array with shape bag_length x emb_size\n",
    "## for each image, there is one emb_size vector encoding. The bag_length, and target information can be stored in the filename. \n",
    "## The data sample is saved as a numpy file: bagLength_15_target_1.npy, and the embedding tensors are saved in the file. \n",
    "import numpy as np\n",
    "import torch \n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "## This folder is best on SSD as the training will randomly seed the files on the disk\n",
    "train_folder = \"../datasets/MNST_train\"\n",
    "test_folder = \"../datasets/MNST_test\"\n",
    "\n",
    "\n",
    "train_embedding = torch.load(\"../datasets/mnst_train_dinov2_small.pt\")\n",
    "train_labels = torch.load(\"../datasets/mnst_train_labels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5482e14-659c-454f-80bd-ac242dc99e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000000/1000000 [06:38<00:00, 2508.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# Simulate bag length as poisson\n",
    "train_embedding = torch.load(\"../datasets/mnst_train_dinov2_small.pt\")\n",
    "train_labels = torch.load(\"../datasets/mnst_train_labels.pt\")\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "n_total_train = len(train_embedding)\n",
    "target_label = 9\n",
    "poisson_length = 25\n",
    "max_length = 40\n",
    "n_train = 1000000\n",
    "labels = []\n",
    "for i in tqdm(range(n_train)):\n",
    "    hashFolder1 = int(hashlib.md5(str(i).encode()).hexdigest(), 16) % 100\n",
    "    hashFolder2 = int(hashlib.md5((str(i) + \"f\").encode()).hexdigest(), 16) % 100\n",
    "    folder = f\"{train_folder}/{hashFolder1}/{hashFolder2}/\"\n",
    "    if os.path.exists(folder) is False:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    bag_length = np.clip(np.random.poisson(poisson_length), 1, max_length)\n",
    "    random_indices = np.random.randint(n_total_train, size=(bag_length))\n",
    "    current_array = np.array(train_embedding[random_indices])\n",
    "    current_label = train_labels[random_indices]\n",
    "    current_label = int(torch.sum(current_label == 9) >= 4)\n",
    "    labels.append(current_label)\n",
    "    filename = \"bagLength_%03d_target_%01d_train_%07d\"%(bag_length, current_label, i)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    np.save(filepath, current_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8cc4b9e-2f2c-4d2e-af0f-42b3100533da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 300000/300000 [01:44<00:00, 2857.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Simulate bag length as poisson\n",
    "test_embedding = torch.load(\"../datasets/mnst_test_dinov2_small.pt\")\n",
    "test_labels = torch.load(\"../datasets/mnst_test_labels.pt\")\n",
    "random_seed = 2\n",
    "np.random.seed(random_seed)\n",
    "n_total_test = len(test_embedding)\n",
    "target_label = 9\n",
    "poisson_length = 25\n",
    "max_length = 40\n",
    "n_test = 300000\n",
    "labels = []\n",
    "for i in tqdm(range(n_test)):\n",
    "    hashFolder1 = int(hashlib.md5(str(i).encode()).hexdigest(), 16) % 100\n",
    "    hashFolder2 = int(hashlib.md5((str(i) + \"f\").encode()).hexdigest(), 16) % 100\n",
    "    folder = f\"{test_folder}/{hashFolder1}/{hashFolder2}/\"\n",
    "    if os.path.exists(folder) is False:\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    bag_length = np.clip(np.random.poisson(poisson_length), 1, max_length)\n",
    "    random_indices = np.random.randint(n_total_test, size=(bag_length))\n",
    "    current_array = np.array(test_embedding[random_indices])\n",
    "    current_label = test_labels[random_indices]\n",
    "    current_label = int(torch.sum(current_label == 9) >= 4)\n",
    "    labels.append(current_label)\n",
    "    filename = \"bagLength_%03d_target_%01d_test_%07d\"%(bag_length, current_label, i)\n",
    "    filepath = os.path.join(folder, filename)\n",
    "    np.save(filepath, current_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8efb94a0-8759-4763-ab8e-01dc6c655d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = []\n",
    "train_folder = \"../datasets/MNST_train\"\n",
    "for hashFolder1 in range(100):\n",
    "    for hashFolder2 in range(100):\n",
    "        folder = f\"{train_folder}/{hashFolder1}/{hashFolder2}/\"\n",
    "        train_files.extend([os.path.join(folder, f_) for f_ in os.listdir(folder) if \"train\" in f_])\n",
    "train_df = pd.DataFrame.from_dict({\"array_path\":train_files})\n",
    "train_df[\"bag_length\"] = train_df[\"array_path\"].apply(lambda x: int(x.split(\"/\")[-1].split(\"_\")[1]))\n",
    "train_df[\"target\"] = train_df[\"array_path\"].apply(lambda x: int(x.split(\"/\")[-1].split(\"_\")[3]))\n",
    "train_df[\"array_path\"] = train_df[\"array_path\"].apply(lambda x: x.strip(\"../\"))\n",
    "train_df.to_csv(\"../datasets/mnst_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b1d575-9251-4942-b087-d82da6b2e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = []\n",
    "test_folder = \"../datasets/MNST_test\"\n",
    "for hashFolder1 in range(100):\n",
    "    for hashFolder2 in range(100):\n",
    "        folder = f\"{test_folder}/{hashFolder1}/{hashFolder2}/\"\n",
    "        test_files.extend([os.path.join(folder, f_) for f_ in os.listdir(folder) if \"test\" in f_])\n",
    "\n",
    "test_df = pd.DataFrame.from_dict({\"array_path\":test_files})\n",
    "test_df[\"bag_length\"] = test_df[\"array_path\"].apply(lambda x: int(x.split(\"/\")[-1].split(\"_\")[1]))\n",
    "test_df[\"target\"] = test_df[\"array_path\"].apply(lambda x: int(x.split(\"/\")[-1].split(\"_\")[3]))\n",
    "test_df[\"array_path\"] = test_df[\"array_path\"].apply(lambda x: x.strip(\"../\"))\n",
    "test_df.to_csv(\"../datasets/mnst_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45278e3-4f8f-4a0d-aa2b-852a8a2b48d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab03649-70a1-46c2-895d-293fce5b7794",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40ac582-ba0b-4807-870d-95e3636f02dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d90524-1df0-43ef-aa4a-2b0cc6a937e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
